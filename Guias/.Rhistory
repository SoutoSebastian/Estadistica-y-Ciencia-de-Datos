)
}
}
View(resultados)
# Inicializamos el data.frame para resultados resumidos
summary_results <- data.frame()
for (nname in names(resultados)) {
for (pname in names(resultados[[nname]])) {
res <- resultados[[nname]][[pname]]
# longitud esperada
mean_len1 <- mean(res$l1)
mean_len2 <- mean(res$l2)
# cubrimiento empírico
cover1 <- mean(res$c1)
cover2 <- mean(res$c2)
# extraer valores numéricos de las etiquetas
n_val <- as.numeric(sub("n = ", "", nname))
p_val <- as.numeric(sub("p = ", "", pname))
# agregamos al data.frame
summary_results <- rbind(summary_results,
data.frame(n = n_val, p = p_val,
mean_len1 = mean_len1,
mean_len2 = mean_len2,
cover1 = cover1,
cover2 = cover2))
}
}
View(summary_results)
# Inicializamos el data.frame para resultados resumidos
summary_results <- data.frame()
for (nname in names(resultados)) {
for (pname in names(resultados[[nname]])) {
res <- resultados[[nname]][[pname]]
# longitud esperada
mean_len1 <- mean(res$l1)
mean_len2 <- mean(res$l2)
# cubrimiento empírico
cover1 <- mean(res$c1)
cover2 <- mean(res$c2)
# extraer valores numéricos de los nombres
n_val <- as.numeric(gsub("[^0-9]", "", nname))
p_val <- as.numeric(gsub("[^0-9\\.]", "", pname))
summary_results <- rbind(summary_results,
data.frame(n = n_val, p = p_val,
mean_len1 = mean_len1,
mean_len2 = mean_len2,
cover1 = cover1,
cover2 = cover2))
}
}
A <- c(250,252,245,258,240,247,251,249,250,243,247,260,238,241,239)
B <- c(330,335,327,329,320,332,337,328,334,326,331,332,328,329,337,341,336,338,325,321)
t.test(A, B, var.equal = TRUE, conf.level = 0.99)$conf.int
sd(A)
sd(B)
n1 <- 15
n2 <- 20
A <- c(250,252,245,258,240,247,251,249,250,243,247,260,238,241,239)
B <- c(330,335,327,329,320,332,337,328,334,326,331,332,328,329,337,341,336,338,325,321)
t.test(A, B, var.equal = TRUE, conf.level = 0.99)$conf.int
sd1(A)
n1 <- 15
n2 <- 20
A <- c(250,252,245,258,240,247,251,249,250,243,247,260,238,241,239)
B <- c(330,335,327,329,320,332,337,328,334,326,331,332,328,329,337,341,336,338,325,321)
t.test(A, B, var.equal = TRUE, conf.level = 0.99)$conf.int
s1 <- sd(A)
s2 <- sd(B)
quantil1 <- qchisq(1-0.005, 33)
quantil2 <- qchisq(0.005,33)
num <- sd1^2*(n1-1) + sd2^2*(n2-1)
n1 <- 15
n2 <- 20
A <- c(250,252,245,258,240,247,251,249,250,243,247,260,238,241,239)
B <- c(330,335,327,329,320,332,337,328,334,326,331,332,328,329,337,341,336,338,325,321)
t.test(A, B, var.equal = TRUE, conf.level = 0.99)$conf.int
s1 <- sd(A)
s2 <- sd(B)
quantil1 <- qchisq(1-0.005, 33)
quantil2 <- qchisq(0.005,33)
num <- s1^2*(n1-1) + s2^2*(n2-1)
izq <- num / quantil1
der <- num / quantil2
intervalo <- c(izq,der)
s1 <- sd(A)
s2 <- sd(B)
quantil1 <- qchisq(1-0.05, 33)
quantil2 <- qchisq(0.05,33)
num <- s1^2*(n1-1) + s2^2*(n2-1)
izq <- sqrt(num / quantil1)
der <- sqrt(num / quantil2)
intervalo <- c(izq,der)
A <- c(41, 37, 36, 39, 44, 42, 38, 37, 35, 32, 39, 30, 40, 41, 37)
B <- c(39, 35.3, 33.5, 36, 42.5, 38, 36, 34.8, 33.2, 29, 29, 36.6, 28.4, 38.5, 39)
Z <- A - B
prom <- mean(Z)
sZ <- sd(Z)
cuantil <- qt(1-0.025,14)
n <- length(Z)
termino <- cuantil * (sZ/sqrt(n))
A <- c(41, 37, 36, 39, 44, 42, 38, 37, 35, 32, 39, 30, 40, 41, 37)
B <- c(39, 35.3, 33.5, 36, 42.5, 38, 36, 34.8, 33.2, 29, 29, 36.6, 28.4, 38.5, 39)
Z <- A - B
prom <- mean(Z)
sZ <- sd(Z)
n <- length(Z)
cuantil <- qt(1-0.025,14)
termino <- cuantil * (sZ/sqrt(n))
izq <- prom - termino
der <- prom + termino
intervalo <- c(izq, der)
qnorm(1-0.005,0,1)
n<- 16
sigma <- 20
mu0 <- 100
test<- function(prom){
estadistico <- (prom - mu0)*sqrt(n)/sigma
if (estadistico >= 1.645){
return(1)
}else{
return(0)
}
}
mu0 <- 100
mu1 <- 110
sigma <- 20
n <- 16
alpha <- 0.05
# Desvío del promedio
sigma_xbar <- sigma / sqrt(n)
# Eje de valores
x <- seq(85, 125, length = 1000)
# Densidades
f0 <- dnorm(x, mean = mu0, sd = sigma_xbar)
f1 <- dnorm(x, mean = mu1, sd = sigma_xbar)
plot(x, f0, type = "l", lwd = 2, col = "blue",
ylab = "Densidad", xlab = expression(bar(X)[n]),
main = "Distribuciones bajo H0 y H1")
lines(x, f1, lwd = 2, col = "red")
# Punto crítico
c <- mu0 + qnorm(1 - alpha) * sigma_xbar
plot(x, f0, type = "l", lwd = 2, col = "blue",
ylab = "Densidad", xlab = expression(bar(X)[n]),
main = "Distribuciones bajo H0 y H1")
lines(x, f1, lwd = 2, col = "red")
# Región crítica (nivel del test)
polygon(c(x[x > c], rev(x[x > c])),
c(f0[x > c], rep(0, sum(x > c))),
col = rgb(0, 0, 1, 0.3), border = NA)
plot(x, f0, type = "l", lwd = 2, col = "blue",
ylab = "Densidad", xlab = expression(bar(X)[n]),
main = "Distribuciones bajo H0 y H1")
lines(x, f1, lwd = 2, col = "red")
# Región crítica (nivel del test)
polygon(c(x[x > c], rev(x[x > c])),
c(f0[x > c], rep(0, sum(x > c))),
col = rgb(0, 0, 1, 0.3), border = NA)
# Potencia (bajo H1)
polygon(c(x[x > c], rev(x[x > c])),
c(f1[x > c], rep(0, sum(x > c))),
col = rgb(1, 0, 0, 0.3), border = NA)
# Línea vertical del punto crítico
abline(v = c, lty = 2)
# Leyenda
legend("topright",
legend = c(expression(H[0]:~mu==100), expression(H[1]:~mu==110),
"Nivel del test", "Potencia"),
col = c("blue", "red", rgb(0,0,1,0.3), rgb(1,0,0,0.3)),
lwd = c(2,2,10,10), bty = "n")
mu0 <- 100
mu1 <- 110
sigma <- 20
alpha <- 0.05
# Caso n = 16
n1 <- 16
sd_xbar1 <- sigma / sqrt(n1)
c16 <- mu0 + qnorm(1 - alpha) * sd_xbar1
# Caso n = 36
n2 <- 36
sd_xbar2 <- sigma / sqrt(n2)
c36 <- mu0 + qnorm(1 - alpha) * sd_xbar2
# Eje x amplio que cubra ambas distribuciones
x <- seq(90, 115, length = 2000)
# Densidades
f0_n16 <- dnorm(x, mean = mu0, sd = sd_xbar1)  # H0, n=16
f1_n16 <- dnorm(x, mean = mu1, sd = sd_xbar1)  # H1, n=16
f0_n36 <- dnorm(x, mean = mu0, sd = sd_xbar2)  # H0, n=36
f1_n36 <- dnorm(x, mean = mu1, sd = sd_xbar2)  # H1, n=36
# Inicio del gráfico: densidad H0 n=16 (base)
plot(x, f0_n16, type = "l", lwd = 2, col = "blue",
ylim = c(0, max(f0_n16, f1_n16, f0_n36, f1_n36)*1.05),
xlab = expression(bar(X)[n]), ylab = "Densidad",
main = "Densidades de " ~ bar(X)[n] ~ " bajo H0 y H1 para n=16 y n=36")
# Agregar las otras densidades
lines(x, f1_n16, lwd = 2, col = "red")
lines(x, f0_n36, lwd = 2, col = "darkblue", lty = 2)  # H0 n=36 (línea discontinua)
lines(x, f1_n36, lwd = 2, col = "darkred",  lty = 2)  # H1 n=36 (línea discontinua)
# Sombrear región de rechazo y potencia para n=16 (azul claro / rojo claro)
ix16 <- which(x > c16)
polygon(c(x[ix16], rev(x[ix16])),
c(f0_n16[ix16], rep(0, length(ix16))),
col = rgb(0,0,1,0.25), border = NA)  # nivel (H0, n=16)
polygon(c(x[ix16], rev(x[ix16])),
c(f1_n16[ix16], rep(0, length(ix16))),
col = rgb(1,0,0,0.15), border = NA)  # potencia (H1, n=16)
# Sombrear región de rechazo y potencia para n=36 (otro color semitransparente)
ix36 <- which(x > c36)
polygon(c(x[ix36], rev(x[ix36])),
c(f0_n36[ix36], rep(0, length(ix36))),
col = rgb(0,0.6,0.8,0.25), border = NA)   # nivel (H0, n=36)
polygon(c(x[ix36], rev(x[ix36])),
c(f1_n36[ix36], rep(0, length(ix36))),
col = rgb(1,0.6,0,0.20), border = NA)     # potencia (H1, n=36)
# Líneas verticales de puntos críticos
abline(v = c16, lty = 2, col = "blue")
abline(v = c36, lty = 2, col = "darkblue")
# Leyenda con valores numéricos
legend("topright",
legend = c(
paste0("H0, n=16 (pdf)"),
paste0("H1, n=16 (pdf)"),
paste0("H0, n=36 (pdf, dashed)"),
paste0("H1, n=36 (pdf, dashed)"),
paste0("c16 = ", round(c16,3)),
paste0("c36 = ", round(c36,3)),
paste0("Potencia n16 = ", round(1 - pnorm((c16 - mu1)/sd_xbar1),3)),
paste0("Potencia n36 = ", round(1 - pnorm((c36 - mu1)/sd_xbar2),3))
),
col = c("blue","red","darkblue","darkred","blue","darkblue","black","black"),
lty = c(1,1,2,2,2,2,NA,NA), bty = "n", cex = 0.8)
qt(0.92, 11)
valor_critico <- qt(0.92, 11)
grasa <- c(21, 18, 19, 16, 18, 24, 22, 19, 24, 14, 18, 15)
promedio <- mean(grasa)
s <- sqrt(sd(grasa))
estadistico <- sqrt(12) *(promedio - 18)/s
valor_critico <- qt(0.92, 11)
grasa <- c(21, 18, 19, 16, 18, 24, 22, 19, 24, 14, 18, 15)
promedio <- mean(grasa)
s <- sd(grasa)
estadistico <- sqrt(12) *(promedio - 18)/s
pchisq(27.552,20)
pchisq(11.1215,21, lower.tail = FALSE)
pchisq(30.556,11,lower.tail = FALSE)
pchisq(12.6,21)
pchisq(12.6, 21, lower.tail = TRUE)
pt(1.0667,11,lower.tail = FALSE)
pchisq(16.4, 20, lower.tail = FALSE)
n <- 50
p0 <- 0.3
alpha <- 0.05
z <- qnorm(1 - alpha/2)
# Vector de valores verdaderos de p
p <- seq(0.05, 0.95, by = 0.001)
# Funciones de potencia
pi_W <- 1 - pnorm(z * sqrt(p0*(1-p0))/sqrt(p*(1-p)) - sqrt(n)*(p - p0)/sqrt(p*(1-p))) +
pnorm(-z * sqrt(p0*(1-p0))/sqrt(p*(1-p)) - sqrt(n)*(p - p0)/sqrt(p*(1-p)))
pi_T <- 1 - pnorm(z - sqrt(n)*(p - p0)/sqrt(p*(1-p))) +
pnorm(-z - sqrt(n)*(p - p0)/sqrt(p*(1-p)))
# Gráfico
plot(p, pi_W, type = "l", col = "blue", lwd = 2,
ylim = c(0,1), xlab = "p verdadero", ylab = "Potencia aproximada",
main = "Funciones de potencia aproximadas (n = 50, p0 = 0.3)")
lines(p, pi_T, col = "red", lwd = 2, lty = 2)
abline(v = p0, lty = 3)
legend("bottomright", legend = c("Test clásico (W)", "Test plug-in (T)"),
col = c("blue", "red"), lwd = 2, lty = c(1,2))
set.seed(123)  # reproducibilidad
n <- 50
p0 <- 0.3
alpha <- 0.05
z <- qnorm(1 - alpha/2)
p_vals <- c(0.03, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.97)
B <- 100000  # cantidad de simulaciones
# vectores donde guardamos las potencias
pi_W <- numeric(length(p_vals))
pi_T <- numeric(length(p_vals))
for (i in seq_along(p_vals)) {
p <- p_vals[i]
# simulamos muestras de tamaño n, repetidas B veces
Xbar <- rbinom(B, n, p) / n
# estadísticos
W <- sqrt(n) * (Xbar - p0) / sqrt(p0*(1 - p0))
T <- sqrt(n) * (Xbar - p0) / sqrt(Xbar*(1 - Xbar))
# rechazos
pi_W[i] <- mean(abs(W) > z)
pi_T[i] <- mean(abs(T) > z)
}
# mostramos resultados
res <- data.frame(p = p_vals, potencia_W = pi_W, potencia_T = pi_T)
print(res)
# gráfico interpolado
plot(p_vals, pi_W, type = "o", pch = 16, col = "blue", ylim = c(0,1),
xlab = "p verdadero", ylab = "Potencia estimada",
main = "Funciones de potencia simuladas (n = 50, p0 = 0.3)")
lines(p_vals, pi_T, type = "o", pch = 17, col = "red", lty = 2)
abline(v = p0, lty = 3)
legend("bottomright", legend = c("Test clásico (W)", "Test plug-in (T)"),
col = c("blue", "red"), lwd = 2, pch = c(16,17), lty = c(1,2))
pbinom(0.96,10,0.4)
qbinom(0.96,10,0.4)
qbinom(0.95,10,0.4)
pbinom(9,10,0.4)
pnorm(0.97)
pnorm(-2.97)
pnorm(0.97) - pnorm(-2.97)
pnorm(0.53)
pnorm(-0.53)
set.seed(2025)
Nsim <- 20000
n1 <- 20
n2 <- 10
alpha <- 0.05
z <- qnorm(1 - alpha)   # percentil 0.95, umbral unilateral
rejects <- 0L
for (i in 1:Nsim) {
x1 <- rnorm(n1, mean = 0, sd = 1)      # bajo H0: mu = 0
T1 <- sqrt(n1) * mean(x1)
if (T1 > z) {
rejects <- rejects + 1
} else {
x2 <- rnorm(n2, mean = 0, sd = 1)
x_all <- c(x1, x2)
T30 <- sqrt(n1 + n2) * mean(x_all)
if (T30 > z) rejects <- rejects + 1
}
}
p_hat <- rejects / Nsim
cat("Rechazo empírico (nivel real):", p_hat, "\n")
set.seed(2025)
Nsim <- 200000
n1 <- 20
n2 <- 10
alpha <- 0.05
z <- qnorm(1 - alpha)   # percentil 0.95, umbral unilateral
rejects <- 0L
for (i in 1:Nsim) {
x1 <- rnorm(n1, mean = 0, sd = 1)      # bajo H0: mu = 0
T1 <- sqrt(n1) * mean(x1)
if (T1 > z) {
rejects <- rejects + 1
} else {
x2 <- rnorm(n2, mean = 0, sd = 1)
x_all <- c(x1, x2)
T30 <- sqrt(n1 + n2) * mean(x_all)
if (T30 > z) rejects <- rejects + 1
}
}
p_hat <- rejects / Nsim
cat("Rechazo empírico (nivel real):", p_hat, "\n")
Nsim <- 200000
n1 <- 20
n2 <- 10
alpha <- 0.05
z <- qnorm(1 - alpha)   # percentil 0.95, umbral unilateral
mus <- c(0.5, 1, 2, 5, 10)
potencias <- 0
for (j in 1:length(mus)){
rejects <- 0L
for (i in 1:Nsim) {
x1 <- rnorm(n1, mean = mus[j], sd = 1)      # bajo H0: mu = 0
T1 <- sqrt(n1) * mean(x1)
if (T1 > z) {
rejects <- rejects + 1
} else {
x2 <- rnorm(n2, mean = mus[j], sd = 1)
x_all <- c(x1, x2)
T30 <- sqrt(n1 + n2) * mean(x_all)
if (T30 > z) rejects <- rejects + 1
}
}
potencias[j] <- rejects / Nsim
}
1 - pnorm(1.645-0.5*sqrt(30))
1 - pnorm(1.645-*sqrt(30))
1 - pnorm(1.645-sqrt(30))
1 - pnorm(1.645-2*sqrt(30))
1 - pnorm(1.645-5*sqrt(30))
1 - pchisq(8.37,6)
2*pt(2.469,18, lower.tail = FALSE)
datos_x <- c(25, 19.5, 16.6, 21.3, 20.7, 16.8)
datos_y <- c(23.8, 19, 15.9, 20.4, 19.6, 15.8)
library(ggplot2)
datos <- data.frame(val = datos_x)
ggplot(datos, aes(sample = val)) +
stat_qq() +
stat_qq_line() +
ggtitle("QQ-Plot de datos_x")
datos <- data.frame(val = datos_y)
ggplot(datos, aes(sample = val)) +
stat_qq() +
stat_qq_line() +
ggtitle("QQ-Plot de datos_y")
datos_x <- c(25, 19.5, 16.6, 21.3, 20.7, 16.8)
datos_y <- c(23.8, 19, 15.9, 20.4, 19.6, 15.8)
datosD <- datos_x - datos_y
library(ggplot2)
datos <- data.frame(val = datosD)
ggplot(datos, aes(sample = val)) +
stat_qq() +
stat_qq_line() +
ggtitle("QQ-Plot de datos_x")
D_raya <- mean(datos)
D_raya <- mean(datosD)
S <- sd(datosD)
sqrt(6)*0.9/S
qf(0.025,9,15,lower.tail = FALSE)
qf(0.025,9,15)
qf(0.05,9,15,lower.tail = FALSE)
qf(0.05,9,15)
datos <- c(24, 21, 27, 28, 23, 22, 36, 24, 33, 14, 25)
S2 <- var(datos)
U_obs <- 10*S2/49
p-val <- pchisq(U-obs,10)
p-val <- pchisq(U_obs,10)
p_val <- pchisq(U_obs,10)
pchisq(U_obs,10)
p_val
S2
U_obs
p_val
sqrt(18) * ((229.94-230)/0.2)
pt(-1.272792, 17)
pt(2.150424665, 110, lower.tail = FALSE) * 2
6.84-7.81- qt(0.005, 110) * sqrt(5.695272727 * (1/55 + 1/57))
sqrt(5.695272727 * (1/55 + 1/57)
)
qt(0.005, 110)
6.84-7.81+ qt(0.005, 110) * sqrt(5.695272727 * (1/55 + 1/57))
6.84-7.81+ qt(0.005, 110, lower.tail = FALSE) * sqrt(5.695272727 * (1/55 + 1/57))
6.84-7.81 - qt(0.005, 110, lower.tail = FALSE) * sqrt(5.695272727 * (1/55 + 1/57))
sa <- 2.76
sb <- 1.92
xa <- 6.84
xb <- 7.81
na <- 55
nb <- 57
sp2 <- ((2.76)^2 * 54 + (1.92^2)) / (55+57-2)
sp2 <- ((2.76)^2 * 54 + (1.92^2)*57) / (55+57-2)
Tobs <- abs(xa - xb)/(sqrt(sp2*(1/na + 1/nb)))
p-val <- 2 * pt(Tobs, 110, lower.tail = FALSE)
pval <- 2 * pt(Tobs, 110, lower.tail = FALSE)
limInf<- xa - xb - qt(0.005, 110, lower.tail = FALSE) * sqrt(sp2 *(1/na + 1/nb))
limSup<- xa - xb + qt(0.005, 110, lower.tail = FALSE) * sqrt(sp2 *(1/na + 1/nb))
sa <- 2.76
sb <- 1.92
xa <- 6.84
xb <- 7.81
na <- 55
nb <- 57
sp2 <- ((2.76)^2 * 54 + (1.92^2)*56) / (55+57-2)
Tobs <- abs(xa - xb)/(sqrt(sp2*(1/na + 1/nb)))
pval <- 2 * pt(Tobs, 110, lower.tail = FALSE)
limInf<- xa - xb - qt(0.005, 110, lower.tail = FALSE) * sqrt(sp2 *(1/na + 1/nb))
limSup<- xa - xb + qt(0.005, 110, lower.tail = FALSE) * sqrt(sp2 *(1/na + 1/nb))
pval
limInf
limSup
p0 <- 0.92
xRaya <- 118/130
tobs <- sqrt(130) *(xRaya - p0)/sqrt(p0*(1-p0))
pVal <- pnorm(tobs)
nmin <- ((-1.645) * sqrt(p0*(1-p0))/(-0.01))^2
cemento <- read.table("cemento.txt")
setwd("C:/Users/Sebastian/Desktop/Estadistica-y-Ciencia-de-Datos/Guias")
cemento <- read.table("cemento.txt")
View(cemento)
cemento <- read.table("cemento.txt", header = TRUE)
matrizCorrelacion <- cor(cemento)
View(matrizCorrelacion)
View(matrizCorrelacion)
modelo <- lm(Y ~ x1 + x2 + x3 + x4 + x5, data = cemento)
modelo <- lm(y ~ x1 + x2 + x3 + x4 + x5, data = cemento)
#estimador de minimos cuadrados:
coeficientes <- coef(modelo)
coeficientes
#tests:
summary(modelo)
anova(modelo)
suma_x <- rowSums(cemento[, c("x1","x2","x3","x4","x5")])
suma_x
modeloSinIntercept <- lm(y ~ x1 + x2 + x3 + x4 + x5 - 1, data = cemento )
summary(modeloSinIntercept)
modeloNuevo <- lm(y ~ x2 + x3 + x4, data = cemento)
modeloNuevo <- lm(y ~ x2 + x3 + x4 -1, data = cemento)
coeficientesNuevos <- coef(modeloNuevo)
modeloNuevo <- lm(y ~ x2 + x3 + x4 -1, data = cemento)
coeficientesNuevos
errores1 <- numeric(nrow(cemento))
errores2 <- numeric(nrow(cemento))
errores3 <- numeric(nrow(cemento))
for(i in 1:nrow(cemento)) {
datos_train <- cemento[-i, ]
datos_test <- cemento[i, , drop = FALSE]
modelo1 <- lm(y ~ x1 + x2 + x3 + x4 + x5, data = datos_train)
modelo2 <- lm(y ~ x1 + x2 + x3 + x4 + x5 - 1, data = datos_train )
modelo3 <- lm(y ~ x2 + x3 + x4 -1, data = datos_train)
prediccion1 <- predict(modelo1, newdata = datos_test)
prediccion2 <- predict(modelo2, newdata = datos_test)
prediccion3 <- predict(modelo3, newdata = datos_test)
error1 <- (prediccion1 - datos_test$y)^2
error2 <- (prediccion2 - datos_test$y)^2
error3 <- (prediccion3 - datos_test$y)^2
errores1[i] <- error1
errores2[i] <- error2
errores3[i] <- error3
}
W1 <- sum(errores1)
W2 <- sum(errores2)
W3 <- sum(errores3)
Ws <- c(W1, W2, W3)
Ws
